{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os, glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_cv(Xtrain, Ytrain):\n",
    "    vec3 = ('charvec', CountVectorizer(analyzer = 'char',ngram_range = (1,6), binary=True, max_df=0.7, lowercase=False))\n",
    "    pipeline = Pipeline([vec3,\n",
    "        ('classifier', LinearSVC(C=0.01))\n",
    "                        ])\n",
    "    print('fitting...')\n",
    "    pipeline.fit(Xtrain, Ytrain)\n",
    "    print('testing using cross-validation...')\n",
    "    Ypredict = cross_val_predict(pipeline, Xtrain, Ytrain, cv=3)\n",
    "    evaluate(Ytrain, Ypredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_final_model(Xtrain, Ytrain, Xtest, Ytest):\n",
    "    vec3 = ('charvec', CountVectorizer(analyzer = 'char',ngram_range = (1,6), binary=True, max_df=0.7, lowercase=False))\n",
    "    pipeline = Pipeline([vec3,\n",
    "        ('classifier', LinearSVC(C=0.01))\n",
    "                        ])\n",
    "    print('fitting...')\n",
    "    pipeline.fit(Xtrain, Ytrain)\n",
    "    print('testing on the test set...')\n",
    "    Ypredict = pipeline.predict(Xtest)\n",
    "    evaluate(Ytest, Ypredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(Ytest, Ypredict):\n",
    "        print(\"\\nAccuracy: \", accuracy_score(Ytest, Ypredict), \"\\n\")\n",
    "        print(\"Classification report:\\n\\n\", classification_report(Ytest, Ypredict))\n",
    "        print(\"Confusion matrix:\\n\\n\", confusion_matrix(Ytest, Ypredict), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.DataFrame(pd.read_csv('training_set_topic_identification', sep='|')).set_index('Zaaknummer (LJN/ECLI)')\n",
    "test_set = pd.DataFrame(pd.read_csv('test_set_topic_identification', sep='|')).set_index('Zaaknummer (LJN/ECLI)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = train_set['extracted_text'].tolist()\n",
    "Ytrain = train_set['is_eviction'].tolist()\n",
    "Xtest = test_set['extracted_text'].tolist()\n",
    "Ytest = test_set['is_eviction'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting...\n",
      "testing using cross-validation...\n",
      "\n",
      "Accuracy:  0.8898809523809523 \n",
      "\n",
      "Classification report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.88      0.89       336\n",
      "        True       0.88      0.90      0.89       336\n",
      "\n",
      "    accuracy                           0.89       672\n",
      "   macro avg       0.89      0.89      0.89       672\n",
      "weighted avg       0.89      0.89      0.89       672\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      " [[294  42]\n",
      " [ 32 304]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model_cv(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting...\n",
      "testing on the test set...\n",
      "\n",
      "Accuracy:  0.88 \n",
      "\n",
      "Classification report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.81      0.87       100\n",
      "        True       0.83      0.95      0.89       100\n",
      "\n",
      "    accuracy                           0.88       200\n",
      "   macro avg       0.89      0.88      0.88       200\n",
      "weighted avg       0.89      0.88      0.88       200\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      " [[81 19]\n",
      " [ 5 95]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_final_model(Xtrain, Ytrain, Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
